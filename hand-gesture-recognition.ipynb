{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23fe17fd-cefe-4fe3-816d-f439765fa0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 488\n",
      "drwxr-xr-x 1 ASUS 197121     0 Jul 30 17:36 .\n",
      "drwxr-xr-x 1 ASUS 197121     0 Jul 30 12:01 ..\n",
      "drwxr-xr-x 1 ASUS 197121     0 Jul 30 17:14 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 ASUS 197121  1285 Jul 30 17:36 hand-gesture-recognition.ipynb\n",
      "drwxr-xr-x 1 ASUS 197121     0 Jul 30 13:33 train\n",
      "-rw-r--r-- 1 ASUS 197121 39651 Jul 30 12:01 train.csv\n",
      "drwxr-xr-x 1 ASUS 197121     0 Jul 30 13:35 val\n",
      "-rw-r--r-- 1 ASUS 197121  5970 Jul 30 12:01 val.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c23b0-e9a4-4b91-94c3-d9f13744078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelBuilder(metaclass = abc.ABCMeta):\n",
    "    #initilaizing project data path\n",
    "    def initialize_path(self, project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.randoml.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path = projcet_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "    #initializing image properties\n",
    "    def initialize_image_properties(self, image_height = 100, image_width = 100):\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.channels = 3\n",
    "        self.num_classes = 5\n",
    "        self.total_frames = 30\n",
    "    #inidializing the batch size, sample frames and number of epoch\n",
    "    def initialize_hyperparameter(self, frame_to_sample=30, batch_size=20, num_epoch=20):\n",
    "        self.frames_to_sample = frames_to_sample\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epoch = num_epoch\n",
    "        \n",
    "    #GENERATOR FUNCTION\n",
    "    def generator(self, source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linespace(0, self.total_frames-1, self.frames_to_sample)).astype(int)\n",
    "        batch_size = self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size            #check\n",
    "            \n",
    "            for batch in range(num_batches):\n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, batch, batch_size, img_idx, augment)\n",
    "                yield batch_data, batch_labels\n",
    "                \n",
    "            remaining_seq = len(%)%batch_size          #check\n",
    "            \n",
    "            if (remaining_seq) != 0):\n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, num_batches, batch_size, img_idx, augment, remaining_seq)\n",
    "                yield batch_data, batch_labels\n",
    "                \n",
    "    def one_batch_data(self, source_path, t, batch, batch_size, img_idx, augment, remaining_seq = 0):\n",
    "        seq_len = reamining_seq if reamining_seq else batch_size\n",
    "        \n",
    "        barch_data = np.zero((seq_len, len(img_idx), self.image_height, self.image_width, self.channels))    #check\n",
    "        batch_labels = np.zeros((seq_len, self.num_classes))    #check\n",
    "        \n",
    "        if (augment): \n",
    "            batch_data_aug = np.zeros((seq_len, len(img_idx), self.image_height, self.image_width, self.channels))   #check\n",
    "        \n",
    "        for folder in range(seq_len):\n",
    "            imgs = os.listdir(source_path + '/' + t[folder + (batch*batch_size)].split(';')[0])       #check\n",
    "            for idx,item in enumerate(img_idx):\n",
    "                #image reading and resizing\n",
    "                image = imread(source_path + '/' + t[folder + (batch*batch_size)].strip().split(';')[0] + '/' + imgs[item]).astype(np.float32)\n",
    "                image_resized = imresize(image, (self.image_height, self.image_width,3))\n",
    "                \n",
    "                #normalizing the images\n",
    "                batch_data[folder, idx, :, :, 0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder, idx, :, :, 1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder, idx, :, :, 2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "                if (augment) :\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30, 30)]]), \n",
    "                                             (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis = 0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis = 0)\n",
    "                    \n",
    "                    #cropping the images to have the targeted gestures and remove the noise from the images\n",
    "                    cropped = shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    image_resized = imresize(cropped, (self.image_height, self.image_width, 3))\n",
    "                    \n",
    "                    batch_data_aug[folder, idx, :, :, 0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder, idx, :, :, 1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder, idx, :, :, 2] = (image_resized[:,:,2])/255\n",
    "                    \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "        if (augment) :\n",
    "            batch_data = np.concatenate([batch_data, batch_data_aug])\n",
    "            batch_labels = np.concatenate([batch_labels, batch_labels])\n",
    "            \n",
    "        return (batch_data, batch_labels)\n",
    "    \n",
    "    def train_model(self, model, augment_data = False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc, augment = augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "        \n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ', '').replace(':', '_') + '/'\n",
    "        \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "            \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\n",
    "        LR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, verbose = 1, patience = 4)\n",
    "        \n",
    "        earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "        callbacks_list = [checkpoint, LR, earlystop]\n",
    "        \n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequence/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "            \n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_val_sequence/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_val_sequences//self.batch_size) + 1\n",
    "            \n",
    "        history = model.fit_generator(train_generator, steps_per_epoch = steps_per_epoch, epoch = self.num_epoch, verbose = 1, callbacks = callbacks_list,\n",
    "                                      validation_data = val_generator, validation_steps = validation_steps, class_weight = None, workers = 1, initial_epoch = 0)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass\n",
    "                                               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
